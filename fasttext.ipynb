{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec Computing\n",
    "##     This file aimed to take advantage of the pretrained model of FastText data to compute the cosine similarity of the tags extracted from \"twreporter\" (692 articles, 2211 tags) and \"newslens\".\n",
    "##     Besides, the cosine similarity of the tags between each documents would be computed, and the result would be taken into consideration as referring to text similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Load fasttext pretrained word vector model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U gensim\n",
    "from __future__ import print_function\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model and save the model\n",
    "zh_model = KeyedVectors.load_word2vec_format('wiki.zh_classical/wiki.zh_classical.vec')\n",
    "zh_model.save('zh_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the tokens \n",
    "words = []\n",
    "for word in zh_model.vocab:\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tokens: 10696\n"
     ]
    }
   ],
   "source": [
    "# Printing out number of tokens available\n",
    "print(\"Number of Tokens: {}\".format(len(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of a word vector: 300\n"
     ]
    }
   ],
   "source": [
    "# Printing out the dimension of a word vector \n",
    "print(\"Dimension of a word vector: {}\".format(\n",
    "    len(zh_model[words[0]])\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector components of a word: [-1.2137e-01  3.7982e-02 -2.7737e-01  3.2376e-01 -1.4194e-01 -5.6606e-02\n",
      " -2.8803e-01  3.5320e-01  1.2195e-01 -1.0090e-01  6.5145e-02  1.3050e-01\n",
      "  2.4721e-01 -5.2645e-01 -3.5504e-01  1.2690e+00  3.9146e-01 -1.4617e-01\n",
      " -1.5835e-02  1.3692e-01  1.6282e-01  2.2253e-01  7.3009e-02 -3.1781e-01\n",
      " -2.2186e-01 -2.1988e-01  3.8458e-01  1.1683e-01 -3.5936e-01  6.4307e-01\n",
      " -2.1387e-01  4.7144e-01  1.6594e-01 -2.8739e-01 -1.4897e-01  3.5061e-01\n",
      " -3.7002e-01  9.1249e-02 -9.1529e-01 -2.4780e-01  1.8264e-01  6.6149e-02\n",
      "  1.9852e-01 -1.5451e-01  5.0628e-01  6.9605e-03 -2.9538e-01 -2.1830e-01\n",
      "  1.3802e-01  7.7120e-01 -2.7467e-01 -5.1889e-01  2.6613e-01 -1.9626e-01\n",
      "  1.5237e+00 -4.6052e-01 -4.1049e-01 -2.7603e-01 -1.6977e-01 -1.8822e-01\n",
      "  2.8506e-01 -1.3644e-01 -3.1863e-01 -7.0669e-02 -7.0327e-02  1.4909e-01\n",
      "  7.3487e-04  3.6984e-01 -4.3169e-01  4.4443e-01  2.2603e-01 -7.3055e-01\n",
      "  4.1653e-01 -1.3083e-01 -5.9000e-03  7.0923e-01  1.1901e-01  5.9910e-01\n",
      " -5.1202e-01  2.1702e-02 -1.2393e-01  7.8061e-02  9.6682e-01 -7.7654e-01\n",
      "  6.4188e-01 -6.0822e-01  2.5323e-01  5.8688e-01  2.3843e-01  1.9630e-01\n",
      "  9.2047e-01  5.7689e-01 -2.8646e-02 -1.9961e-01 -2.0940e-01  5.2966e-01\n",
      " -1.8605e-01  3.4778e-01 -7.5198e-01  7.3509e-02  1.3457e-01  4.3234e-01\n",
      "  7.6060e-01 -7.9919e-02  6.4554e-01  1.8830e-01  1.2442e-01  2.8076e-01\n",
      "  3.0869e-01  7.6339e-01 -3.7975e-01  2.8551e-01  1.2673e-01 -1.2352e-01\n",
      "  4.3069e-03 -3.7963e-01 -2.4773e-04  2.3466e-01 -4.2045e-01 -1.7681e-01\n",
      " -4.2512e-02  2.0559e-01  4.2440e-01 -3.6712e-02  5.1024e-01  3.2377e-01\n",
      "  2.9944e-01  2.0156e-01 -2.0025e-01  5.8166e-02 -3.4503e-01 -2.0706e-02\n",
      " -2.2288e-01 -2.0542e-01  2.7100e-01  3.4399e-01 -2.4368e-01  1.2789e-01\n",
      " -2.5595e-01 -1.5846e-01 -8.1177e-02  5.2176e-01  1.7849e-02 -1.8657e-01\n",
      "  9.0233e-02  2.6575e-01 -3.9257e-02  2.4042e-01 -1.6969e-01  6.7170e-01\n",
      " -5.9699e-01 -4.3351e-01  3.4983e-01 -7.1089e-02 -8.2204e-02 -1.1054e-01\n",
      " -5.0407e-02 -1.7826e-01  3.3033e-01  1.0716e-02  8.3344e-02  3.6490e-01\n",
      " -5.4200e-02 -7.7043e-02  4.6669e-01 -3.9801e-02 -4.0093e-02 -2.9350e-01\n",
      "  1.8610e-01  3.4987e-01 -1.9409e-02  4.1592e-01 -1.4850e-01 -4.2504e-01\n",
      " -2.7502e-01 -7.9345e-01 -2.2840e-01 -1.0118e-01  5.1788e-01  1.8316e-01\n",
      " -5.6776e-01  2.7304e-01  2.1479e-01 -1.3365e-01  1.2004e-02 -4.3523e-01\n",
      "  2.6070e-01  4.9690e-01 -6.4313e-01  3.0715e-01 -2.6669e-02  2.7746e-01\n",
      "  2.2652e-01 -2.9974e-01 -5.0468e-01 -1.5949e-01 -5.0552e-01 -4.1777e-02\n",
      " -8.9214e-02 -2.1142e-01  5.8746e-01  6.9137e-03 -2.3843e-01  9.3862e-02\n",
      " -3.9805e-01 -2.0408e-01 -1.2816e-01 -3.4624e-01 -1.5188e-01 -4.9381e-01\n",
      " -6.5804e-03  4.6254e-01 -2.6796e-01 -2.1748e-01  2.2381e-01  3.1034e-02\n",
      " -3.4652e-01 -9.5402e-02 -1.5778e-01 -3.3699e-01  2.5074e-01  1.8251e-01\n",
      "  1.8275e-01  1.7857e-04 -3.2345e-01  3.4869e-01 -4.1628e-01 -2.1527e-01\n",
      " -5.2577e-01  3.0114e-01  7.3897e-02  1.8451e-01  1.4639e-01  4.1393e-02\n",
      "  1.2715e-02 -1.3716e-01  1.4022e-01 -2.2752e-01 -3.7152e-02 -1.6985e-01\n",
      "  7.7215e-02 -6.3860e-01  4.8287e-01  5.2509e-01  1.9601e-01 -3.0002e-01\n",
      "  7.8856e-03  7.4645e-01 -8.3175e-01  2.1368e-02  3.2868e-01 -3.5684e-01\n",
      " -8.9086e-01  5.2632e-01  1.1411e-01 -4.4502e-01  7.5701e-02  7.2878e-01\n",
      "  2.7832e-02 -1.8314e-02  4.2046e-01  2.7749e-01  6.1826e-01  1.9561e-01\n",
      "  2.4735e-01 -1.6281e-01  8.9971e-02 -1.4831e-02 -3.9794e-01  3.7866e-01\n",
      " -1.2551e-01  7.9488e-02  4.1407e-01 -5.4583e-02 -6.0507e-01  1.9980e-01\n",
      "  6.4106e-01 -1.1263e-01 -8.2028e-02  2.2733e-01  5.8656e-01  5.4221e-01\n",
      "  2.3868e-01 -2.2337e-01  3.2734e-01 -2.0942e-01  5.3823e-01  1.7916e-01\n",
      "  6.1767e-02  3.2603e-01 -7.2062e-01 -2.8951e-01  2.7660e-01 -6.6918e-03\n",
      " -4.2566e-01 -2.1150e-01 -1.2613e-01 -1.3505e-01 -4.4744e-01 -2.4053e-01]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Print out the vector of a word \n",
    "print(\"Vector components of a word: {}\".format(\n",
    "    zh_model[words[0]]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "zh_model['微軟']\n",
    "similarity = zh_model.similarity('你', '微軟')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a word \n",
    "find_similar_to = '自由'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: 微軟, Similarity: 0.83\n",
      "Word: 協作, Similarity: 0.82\n",
      "Word: 書面, Similarity: 0.82\n",
      "Word: 吾等, Similarity: 0.82\n",
      "Word: 相關, Similarity: 0.82\n",
      "Word: 營運, Similarity: 0.82\n",
      "Word: 俄文, Similarity: 0.81\n",
      "Word: 計畫, Similarity: 0.81\n",
      "Word: 協會, Similarity: 0.81\n",
      "Word: 戶名, Similarity: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "# Finding out similar words [default= top 10]\n",
    "for similar_word in zh_model.similar_by_word(find_similar_to):\n",
    "    print(\"Word: {0}, Similarity: {1:.2f}\".format(\n",
    "        similar_word[0], similar_word[1]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Access the tags of each documents and get their cosine similarities (twreporter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "with open('./tags_seg_twreporter_cl.csv', newline='', encoding=\"big5\",\n",
    "                 errors='ignore') as csvfile:\n",
    "    rows_1 = csv.reader(csvfile, delimiter=',')\n",
    "    \n",
    "    totoftags = 0\n",
    "    \n",
    "    alltags = []\n",
    "    for row in rows_1:\n",
    "        row_str = ''.join(row[1])        \n",
    "        tags_1 = row_str.split(',')\n",
    "        \n",
    "        for tag in tags_1:\n",
    "            alltags.append(tag)\n",
    "        \n",
    "\n",
    "with open('./tags_seg_newslens-post_ed.csv', newline='', encoding=\"big5\",\n",
    "                 errors='ignore') as csvfile:\n",
    "    rows_2 = csv.reader(csvfile, delimiter=',')\n",
    "    \n",
    "    for row in rows_2:        \n",
    "        row_str = ''.join(row[1])        \n",
    "        tags_2 = row_str.split(',')\n",
    "            \n",
    "        for tag in tags_2:\n",
    "            alltags.append(tag)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25091"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alltags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['中國', ' 人權', ' Tibet', ' 新疆', ' Chinese', ' -', ' English', '  ', ' stories']"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = {}\n",
    "for t in tags:\n",
    "    if t in model.vocab:  ## 確認在訓練資療集當中是否有這個字，沒有這一步會出現錯誤\n",
    "        df[t] = [for term, score in model.most_similar(t)]  ## 原本會回傳(term, score)的List，現在只抓term\n",
    "    else:\n",
    "        print(t, ' not in vocab')\n",
    "df = pd.DataFrame(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reference\n",
    "# Step 1. https://blog.manash.me/how-to-use-pre-trained-word-vectors-from-facebooks-fasttext-a71e6d55f27\n",
    "# Step 2-1. https://blog.gtwang.org/programming/python-csv-file-reading-and-writing-tutorial/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
